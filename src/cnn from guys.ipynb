{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "458a2941-e431-4937-8222-f01d38a07d91",
   "metadata": {},
   "source": [
    "Audiospec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88864199-c224-493d-8c4f-bfaa083710d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "import scipy.io.wavfile as wav\n",
    "from numpy.lib import stride_tricks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\" short time fourier transform of audio signal \"\"\"\n",
    "def stft(sig, frameSize, overlapFac=0.5, window=np.hanning):\n",
    "    win = window(frameSize)\n",
    "    hopSize = int(frameSize - np.floor(overlapFac * frameSize))\n",
    "    \n",
    "    # zeros at beginning (thus center of 1st window should be for sample nr. 0)\n",
    "    samples = np.append(np.zeros(np.int64(np.floor(frameSize/2.0))), sig)    \n",
    "    # cols for windowing\n",
    "    cols = np.int64(np.ceil( (len(samples) - frameSize) / float(hopSize)) + 1)\n",
    "    # zeros at end (thus samples can be fully covered by frames)\n",
    "    samples = np.append(samples, np.zeros(frameSize))\n",
    "    \n",
    "    frames = stride_tricks.as_strided(\n",
    "            samples, shape=(cols, frameSize),\n",
    "            strides=(samples.strides[0]*hopSize, samples.strides[0])).copy()\n",
    "    frames *= win\n",
    "    \n",
    "    return np.fft.rfft(frames)    \n",
    "    \n",
    "\"\"\" scale frequency axis logarithmically \"\"\"    \n",
    "def logscale_spec(spec, sr=44100, factor=20.):\n",
    "    timebins, freqbins = np.shape(spec)\n",
    "\n",
    "    scale = np.linspace(0, 1, freqbins) ** factor\n",
    "    scale *= (freqbins-1)/max(scale)\n",
    "    scale = np.unique(np.round(scale))\n",
    "    scale = np.int64(scale)\n",
    "    \n",
    "    # create spectrogram with new freq bins\n",
    "    newspec = np.complex128(np.zeros([timebins, len(scale)]))\n",
    "    for i in range(0, len(scale)):\n",
    "        if i == len(scale)-1:\n",
    "            newspec[:,i] = np.sum(spec[:,scale[i]:], axis=1)\n",
    "        else:        \n",
    "            newspec[:,i] = np.sum(spec[:,scale[i]:scale[i+1]], axis=1)\n",
    "    \n",
    "    # list center freq of bins\n",
    "    allfreqs = np.abs(np.fft.fftfreq(freqbins*2, 1./sr)[:freqbins+1])\n",
    "    freqs = []\n",
    "    for i in range(0, len(scale)):\n",
    "        if i == len(scale)-1:\n",
    "            freqs += [np.mean(allfreqs[scale[i]:])]\n",
    "        else:\n",
    "            freqs += [np.mean(allfreqs[scale[i]:scale[i+1]])]\n",
    "    \n",
    "    return newspec, freqs\n",
    "\n",
    "\"\"\" plot spectrogram\"\"\"\n",
    "def plotstft(samples, samplerate, binsize=2**10, \n",
    "        plotpath=None, colormap=\"jet\", plot_artifacts=True):\n",
    "    s = stft(samples, binsize)\n",
    "    \n",
    "    sshow, freq = logscale_spec(s, factor=1.0, sr=samplerate)\n",
    "    ims = 20.*np.log10(np.abs(sshow)/10e-6) # amplitude to decibel\n",
    "    \n",
    "    timebins, freqbins = np.shape(ims)\n",
    "    \n",
    "    plt.figure(figsize=(15, 7.5))\n",
    "    plt.imshow(np.transpose(ims), origin=\"lower\", \n",
    "            aspect=\"auto\", cmap=colormap, interpolation=\"none\")\n",
    "\n",
    "    if not plot_artifacts:\n",
    "      plt.axis('off')\n",
    "    else:\n",
    "      plt.colorbar()\n",
    "\n",
    "      plt.xlabel(\"time (s)\")\n",
    "      plt.ylabel(\"frequency (hz)\")\n",
    "      plt.xlim([0, timebins-1])\n",
    "      plt.ylim([0, freqbins])\n",
    "\n",
    "      xlocs = np.float32(np.linspace(0, timebins-1, 5))\n",
    "      plt.xticks(xlocs, [\"%.02f\" % l for l in \n",
    "          ((xlocs*len(samples)/timebins)+(0.5*binsize))/samplerate])\n",
    "\n",
    "      ylocs = np.int16(np.round(np.linspace(0, freqbins-1, 10)))\n",
    "      plt.yticks(ylocs, [\"%.02f\" % freq[i] for i in ylocs])\n",
    "    \n",
    "    if plotpath:\n",
    "        plt.savefig(plotpath, bbox_inches=\"tight\")\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.clf()\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb0bf64-9744-4b48-8008-305d1a030095",
   "metadata": {},
   "source": [
    "Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e512c31-6c2a-4eb7-ba65-205f8ca1aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "import scipy.io.wavfile as wav\n",
    "from numpy.lib import stride_tricks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\" short time fourier transform of audio signal \"\"\"\n",
    "def stft(sig, frameSize, overlapFac=0.5, window=np.hanning):\n",
    "    win = window(frameSize)\n",
    "    hopSize = int(frameSize - np.floor(overlapFac * frameSize))\n",
    "    \n",
    "    # zeros at beginning (thus center of 1st window should be for sample nr. 0)\n",
    "    samples = np.append(np.zeros(np.int64(np.floor(frameSize/2.0))), sig)    \n",
    "    # cols for windowing\n",
    "    cols = np.int64(np.ceil( (len(samples) - frameSize) / float(hopSize)) + 1)\n",
    "    # zeros at end (thus samples can be fully covered by frames)\n",
    "    samples = np.append(samples, np.zeros(frameSize))\n",
    "    \n",
    "    frames = stride_tricks.as_strided(\n",
    "            samples, shape=(cols, frameSize),\n",
    "            strides=(samples.strides[0]*hopSize, samples.strides[0])).copy()\n",
    "    frames *= win\n",
    "    \n",
    "    return np.fft.rfft(frames)    \n",
    "    \n",
    "\"\"\" scale frequency axis logarithmically \"\"\"    \n",
    "def logscale_spec(spec, sr=44100, factor=20.):\n",
    "    timebins, freqbins = np.shape(spec)\n",
    "\n",
    "    scale = np.linspace(0, 1, freqbins) ** factor\n",
    "    scale *= (freqbins-1)/max(scale)\n",
    "    scale = np.unique(np.round(scale))\n",
    "    scale = np.int64(scale)\n",
    "    \n",
    "    # create spectrogram with new freq bins\n",
    "    newspec = np.complex128(np.zeros([timebins, len(scale)]))\n",
    "    for i in range(0, len(scale)):\n",
    "        if i == len(scale)-1:\n",
    "            newspec[:,i] = np.sum(spec[:,scale[i]:], axis=1)\n",
    "        else:        \n",
    "            newspec[:,i] = np.sum(spec[:,scale[i]:scale[i+1]], axis=1)\n",
    "    \n",
    "    # list center freq of bins\n",
    "    allfreqs = np.abs(np.fft.fftfreq(freqbins*2, 1./sr)[:freqbins+1])\n",
    "    freqs = []\n",
    "    for i in range(0, len(scale)):\n",
    "        if i == len(scale)-1:\n",
    "            freqs += [np.mean(allfreqs[scale[i]:])]\n",
    "        else:\n",
    "            freqs += [np.mean(allfreqs[scale[i]:scale[i+1]])]\n",
    "    \n",
    "    return newspec, freqs\n",
    "\n",
    "\"\"\" plot spectrogram\"\"\"\n",
    "def plotstft(samples, samplerate, binsize=2**10, \n",
    "        plotpath=None, colormap=\"jet\", plot_artifacts=True):\n",
    "    s = stft(samples, binsize)\n",
    "    \n",
    "    sshow, freq = logscale_spec(s, factor=1.0, sr=samplerate)\n",
    "    ims = 20.*np.log10(np.abs(sshow)/10e-6) # amplitude to decibel\n",
    "    \n",
    "    timebins, freqbins = np.shape(ims)\n",
    "    \n",
    "    plt.figure(figsize=(15, 7.5))\n",
    "    plt.imshow(np.transpose(ims), origin=\"lower\", \n",
    "            aspect=\"auto\", cmap=colormap, interpolation=\"none\")\n",
    "\n",
    "    if not plot_artifacts:\n",
    "      plt.axis('off')\n",
    "    else:\n",
    "      plt.colorbar()\n",
    "\n",
    "      plt.xlabel(\"time (s)\")\n",
    "      plt.ylabel(\"frequency (hz)\")\n",
    "      plt.xlim([0, timebins-1])\n",
    "      plt.ylim([0, freqbins])\n",
    "\n",
    "      xlocs = np.float32(np.linspace(0, timebins-1, 5))\n",
    "      plt.xticks(xlocs, [\"%.02f\" % l for l in \n",
    "          ((xlocs*len(samples)/timebins)+(0.5*binsize))/samplerate])\n",
    "\n",
    "      ylocs = np.int16(np.round(np.linspace(0, freqbins-1, 10)))\n",
    "      plt.yticks(ylocs, [\"%.02f\" % freq[i] for i in ylocs])\n",
    "    \n",
    "    if plotpath:\n",
    "        plt.savefig(plotpath, bbox_inches=\"tight\")\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.clf()\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55344816-5c2c-4a4c-a8bb-7e3e23d394b8",
   "metadata": {},
   "source": [
    "CQT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c40d6f4-5eee-4520-8098-ee2097bd5560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_cqt(song, path):\n",
    "  plt.figure(figsize=(7.5, 3.75))\n",
    "  y, sr = librosa.load(song)\n",
    "  C = librosa.cqt(y, sr=sr)\n",
    "  librosa.display.specshow(librosa.amplitude_to_db(C, ref=np.max),\n",
    "                            sr=sr)\n",
    "  plt.axis('off')\n",
    "  plt.savefig(path, bbox_inches=\"tight\")\n",
    "  plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f19da87-b78e-40d7-afdc-158ab8999306",
   "metadata": {},
   "source": [
    "Split midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc6c93ca-48e0-49a0-974e-57fc0b81a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mido\n",
    "from mido import MidiFile, MidiTrack, Message, MetaMessage\n",
    "from os import listdir\n",
    "from os.path import isfile, split, join\n",
    "import argparse\n",
    "\n",
    "def split_midi(mid_file, target_dir, default_tempo=500000, target_segment_len=1):\n",
    "  '''Split midi file into many chunks'''\n",
    "  song_name = split(mid_file)[-1][:-4]\n",
    "  mid = MidiFile(mid_file)\n",
    "\n",
    "  # identify the meta messages\n",
    "  metas = []\n",
    "  tempo = default_tempo\n",
    "  for msg in mid:\n",
    "    if msg.type == 'set_tempo':\n",
    "      tempo = msg.tempo\n",
    "    if msg.is_meta:\n",
    "      metas.append(msg)\n",
    "  for meta in metas:\n",
    "    meta.time = int(mido.second2tick(meta.time, mid.ticks_per_beat, tempo))\n",
    "\n",
    "  target = MidiFile()\n",
    "  track = MidiTrack()\n",
    "  track.extend(metas)\n",
    "  target.tracks.append(track)\n",
    "  prefix = 0\n",
    "  time_elapsed = 0\n",
    "  for msg in mid:\n",
    "    # Skip non-note related messages\n",
    "    if msg.is_meta:\n",
    "      continue\n",
    "    time_elapsed += msg.time\n",
    "    if msg.type != 'end_of_track':\n",
    "      msg.time = int(mido.second2tick(msg.time, mid.ticks_per_beat, tempo))\n",
    "      track.append(msg)\n",
    "    if msg.type == 'end_of_track' or time_elapsed >= target_segment_len:\n",
    "      track.append(MetaMessage('end_of_track'))\n",
    "      target.save(join(target_dir, song_name + '_{}.mid'.format(prefix)))\n",
    "      target = MidiFile()\n",
    "      track = MidiTrack()\n",
    "      track.extend(metas)\n",
    "      target.tracks.append(track)\n",
    "      time_elapsed = 0\n",
    "      prefix += 1\n",
    "\n",
    "\n",
    "def merge_midi(midis, input_dir, output, default_tempo=500000):\n",
    "  '''Merge midi files into one'''\n",
    "  pairs = [(int(x[:-4].split('_')[-1]), x) for x in midis]\n",
    "  pairs = sorted(pairs, key=lambda x: x[0])\n",
    "  midis = [join(input_dir, x[1]) for x in pairs]\n",
    "\n",
    "  mid = MidiFile(midis[0])\n",
    "  # identify the meta messages\n",
    "  metas = []\n",
    "  # tempo = default_tempo\n",
    "  tempo = default_tempo // 2\n",
    "  for msg in mid:\n",
    "    if msg.type == 'set_tempo':\n",
    "      tempo = msg.tempo\n",
    "    if msg.is_meta:\n",
    "      metas.append(msg)\n",
    "  for meta in metas:\n",
    "    meta.time = int(mido.second2tick(meta.time, mid.ticks_per_beat, tempo))\n",
    "  \n",
    "  target = MidiFile()\n",
    "  track = MidiTrack()\n",
    "  track.extend(metas)\n",
    "  target.tracks.append(track)\n",
    "  for midi in midis:\n",
    "    mid = MidiFile(midi)\n",
    "    for msg in mid:\n",
    "      if msg.is_meta:\n",
    "        continue\n",
    "      if msg.type != 'end_of_track':\n",
    "        msg.time = int(mido.second2tick(msg.time, mid.ticks_per_beat, tempo))\n",
    "        track.append(msg)\n",
    "\n",
    "  track.append(MetaMessage('end_of_track'))\n",
    "  target.save(output)\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "  '''Parse arguments'''\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument('input_dir', type=str)\n",
    "  parser.add_argument('target_dir', type=str)\n",
    "  parser.add_argument('-l', '--length', default=1, type=float)\n",
    "  parser.add_argument('-m', '--merge', action='store_true')\n",
    "  return parser.parse_args()\n",
    "\n",
    "\n",
    "def main():\n",
    "  args = parse_args()\n",
    "  input_dir = args.input_dir\n",
    "  target_dir = args.target_dir\n",
    "  length = args.length\n",
    "\n",
    "  # Get all the input midi files\n",
    "  midis = [x for x in listdir(input_dir) if x.endswith('.mid')]\n",
    "\n",
    "  if args.merge:\n",
    "    merge_midi(midis, input_dir, target_dir)\n",
    "  else:\n",
    "    for midi in midis:\n",
    "      print(midi)\n",
    "      try:\n",
    "        split_midi(join(input_dir, midi), target_dir, target_segment_len=length)\n",
    "      except:\n",
    "        print('\\tProblem!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d00bf3a-d990-46fd-926e-8e2904395cd5",
   "metadata": {},
   "source": [
    "utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3aa199b4-6321-467b-a83c-8af7bb7f0756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\"\"\"\n",
    "Simple function for converting Pretty MIDI object into one-hot encoding\n",
    "/ piano-roll-like to be used for machine learning.\n",
    "\"\"\"\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "def pretty_midi_to_one_hot(pm, fs=100):\n",
    "    \"\"\"Compute a one hot matrix of a pretty midi object\n",
    "    Parameters\n",
    "    ----------\n",
    "    pm : pretty_midi.PrettyMIDI\n",
    "        A pretty_midi.PrettyMIDI class instance describing\n",
    "        the piano roll.\n",
    "    fs : int\n",
    "        Sampling frequency of the columns, i.e. each column is spaced apart\n",
    "        by ``1./fs`` seconds.\n",
    "    Returns\n",
    "    -------\n",
    "    one_hot : np.ndarray, shape=(128,times.shape[0])\n",
    "        Piano roll of this instrument. 1 represents Note Ons,\n",
    "        -1 represents Note offs, 0 represents constant/do-nothing\n",
    "    \"\"\"\n",
    "\n",
    "    # Allocate a matrix of zeros - we will add in as we go\n",
    "    one_hots = []\n",
    "\n",
    "    if len(pm.instruments) < 1:\n",
    "        return 0\n",
    "\n",
    "    for instrument in pm.instruments:\n",
    "        one_hot = np.zeros((128, int(fs*instrument.get_end_time())+1))\n",
    "        for note in instrument.notes:\n",
    "            # note on\n",
    "            one_hot[note.pitch, int(note.start*fs)] = 1\n",
    "            # print('note on',note.pitch, int(note.start*fs))\n",
    "            # note off\n",
    "            one_hot[note.pitch, int(note.end*fs)] = 0\n",
    "            # print('note off',note.pitch, int(note.end*fs))\n",
    "        one_hots.append(one_hot)\n",
    "\n",
    "    one_hot = np.zeros((128, np.max([o.shape[1] for o in one_hots])))\n",
    "    for o in one_hots:\n",
    "        one_hot[:, :o.shape[1]] += o\n",
    "\n",
    "    one_hot = np.clip(one_hot,-1,1)\n",
    "    return one_hot\n",
    "\n",
    "def one_hot_to_pretty_midi(one_hot, fs=100, program=1,bpm=120):\n",
    "    '''Convert a Piano Roll array into a PrettyMidi object\n",
    "     with a single instrument.\n",
    "    Parameters\n",
    "    ----------\n",
    "    piano_roll : np.ndarray, shape=(128,time)\n",
    "        Piano roll of one instrument\n",
    "    fs : int\n",
    "        Sampling frequency of the columns, i.e. each column is spaced apart\n",
    "        by ``1./fs`` seconds.\n",
    "    program : int\n",
    "        The program number of the instrument.\n",
    "    bpm : int\n",
    "        Beats per minute, used to decide when to re-emphasize notes left on.\n",
    "    Returns\n",
    "    -------\n",
    "    midi_object : pretty_midi.PrettyMIDI\n",
    "        A pretty_midi.PrettyMIDI class instance describing\n",
    "        the piano roll.\n",
    "    '''\n",
    "    notes, frames = one_hot.shape\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    instrument = pretty_midi.Instrument(program=program)\n",
    "\n",
    "    # prepend, append zeros so we can acknowledge inital and ending events\n",
    "    piano_roll = np.hstack((np.zeros((notes, 1)),\n",
    "                            one_hot,\n",
    "                            np.zeros((notes, 1))))\n",
    "\n",
    "    # use changes to find note on / note off events\n",
    "    changes = np.nonzero(np.diff(piano_roll).T)\n",
    "\n",
    "    # keep track of note on times and notes currently playing\n",
    "    note_on_time = np.zeros(notes)\n",
    "    current_notes = np.zeros(notes)\n",
    "\n",
    "    bps = bpm / 60\n",
    "    beat_interval = fs / bps\n",
    "    strong_beats = beat_interval * 2 #(for 4/4 timing)\n",
    "\n",
    "    last_beat_time = 0\n",
    "\n",
    "    for time, note in zip(*changes):\n",
    "        change = piano_roll[note, time + 1]\n",
    "\n",
    "        if time >= last_beat_time + beat_interval:\n",
    "            for note in current_notes:\n",
    "                time = time / fs\n",
    "\n",
    "        time = time / fs\n",
    "        if change == 1:\n",
    "            # note on\n",
    "            if current_notes[note] == 0:\n",
    "                # from note off\n",
    "                note_on_time[note] = time\n",
    "                current_notes[note] = 1\n",
    "            else:\n",
    "                #re-articulate (later in code)\n",
    "                '''pm_note = pretty_midi.Note(\n",
    "                        velocity=100, #don't care fer now\n",
    "                        pitch=note,\n",
    "                        start=note_on_time[note],\n",
    "                        end=time)\n",
    "                instrument.notes.append(pm_note)\n",
    "                note_on_time[note] = time\n",
    "                current_notes[note] = 1'''\n",
    "        elif change == 0:\n",
    "            #note off\n",
    "            pm_note = pretty_midi.Note(\n",
    "                    velocity=100, #don't care fer now\n",
    "                    pitch=note,\n",
    "                    start=note_on_time[note],\n",
    "                    end=time)\n",
    "            current_notes[note] = 0\n",
    "            instrument.notes.append(pm_note)\n",
    "    pm.instruments.append(instrument)\n",
    "    return pm\n",
    "\n",
    "def slice_to_categories(piano_roll):\n",
    "    notes_list = np.zeros(128)\n",
    "    notes = np.nonzero(piano_roll)[0]\n",
    "    notes = np.unique(notes)\n",
    "\n",
    "    for note in notes:\n",
    "        notes_list[note] = 1\n",
    "\n",
    "    return notes_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905e8d5f-5e3e-4142-96fa-b6f9a1939a1b",
   "metadata": {},
   "source": [
    "cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dc99f8-df25-4a90-90ae-ff3385c4b428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ad736bd-acfa-4fcb-b536-27fcb8e26a90",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '-f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 164\u001b[0m\n\u001b[1;32m    160\u001b[0m     x_test \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[1;32m    161\u001b[0m     train(x_train, y_train, x_test, y_test)\n\u001b[0;32m--> 164\u001b[0m \u001b[43mrun_cnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 117\u001b[0m, in \u001b[0;36mrun_cnn\u001b[0;34m(jpg_path, midi_path)\u001b[0m\n\u001b[1;32m    115\u001b[0m img \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    116\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjpg_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mprint\u001b[39m(filename)\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m# filename = \"daylight_128.jpg\"\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '-f'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Dense, Flatten, Reshape, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, CSVLogger\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from  skimage.measure import block_reduce\n",
    "\n",
    "from PIL import Image\n",
    "#import utils\n",
    "import pretty_midi\n",
    "import os, os.path\n",
    "import sys\n",
    "\n",
    "def create_model():\n",
    "    img_x, img_y = 145, 49\n",
    "    input_shape = (img_x, img_y, 3)\n",
    "    num_classes = 128\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(5,5), strides=(1,1),\n",
    "        activation='tanh',\n",
    "        input_shape=input_shape))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Conv2D(64, (3,3), activation='tanh'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    #model.add(Conv2D(64, (5,5), activation='relu'))\n",
    "    # Final output layer\n",
    "    #model.add(Conv2D(128, (5,5), activation='sigmoid'))\n",
    "    #model.add(Flatten())\n",
    "    model.add(Flatten())\n",
    "    #model.add(Dense(64, activation='sigmoid'))\n",
    "    model.add(Dense(num_classes, activation='sigmoid'))\n",
    "    return model\n",
    "    \n",
    "\n",
    "class AccuracyHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.acc = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.acc.append(logs.get('acc'))\n",
    "\n",
    "\n",
    "def train(x_train, y_train, x_test, y_test):\n",
    "    batch_size = 64\n",
    "    num_classes = 128\n",
    "    epochs = 100\n",
    "\n",
    "    # input image dimensions\n",
    "    img_x, img_y = 624, 1222\n",
    "\n",
    "    path = '/mnt/d/Workspace/EE379K/DSL_Final/models'\n",
    "    #path = '/mnt/c/Users/chau/Documents/models'\n",
    "    model_ckpt = os.path.join(path,'ckpt.h5')\n",
    "    \n",
    "    #x_train = x_train.reshape(x_train.shape[0], img_x, img_y, 3)\n",
    "    #x_test = x_test.reshape(x_train.shape[0], img_x, img_y, 3)\n",
    "    \n",
    "    # Convert data to right type\n",
    "    #x_train = x_train.astype('float32')\n",
    "    #x_test = x_test.astype('float32')\n",
    "    #x_train /= 255\n",
    "    #x_test /= 255\n",
    "    #print(x_train)\n",
    "    #print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    model = create_model()\n",
    "    model.compile(loss=keras.losses.binary_crossentropy,\n",
    "            optimizer=keras.optimizers.Adam(lr=.0001, decay=1e-6),\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "    history = AccuracyHistory()\n",
    "\n",
    "    checkpoint = ModelCheckpoint(model_ckpt,\n",
    "            monitor='val_loss',\n",
    "            verbose=1,\n",
    "            save_best_only=True,\n",
    "            mode='min')\n",
    "    early_stop = EarlyStopping(patience=5, \n",
    "            monitor='val_loss',\n",
    "            verbose=1, mode='min')\n",
    "    callbacks = [history, checkpoint,early_stop]\n",
    "    \n",
    "    model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            validation_data=(x_test, y_test),\n",
    "            callbacks=callbacks)\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    plt.plot(range(1,101), history.acc)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.savefig('loss.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def run_cnn(jpg_path, midi_path):\n",
    "    # x is spectrogram, y is MIDI\n",
    "    #jpg_path = '/mnt/d/Workspace/EE379K/data/spectrograms'\n",
    "    #midi_path = '/mnt/d/Workspace/EE379K/data/split_midi'\n",
    "    #jpg_path = '/mnt/c/Users/chau/Documents/spectrograms'\n",
    "    #midi_path = '/mnt/c/Users/chau/Documents/split_midi'\n",
    "    x_train, y_train = [], []\n",
    "    img = []\n",
    "    i = 0\n",
    "    for filename in os.listdir(jpg_path):\n",
    "        print(filename)\n",
    "        # filename = \"daylight_128.jpg\"\n",
    "        m_fn = filename.replace(\".jpg\", \".mid\")\n",
    "        if os.path.isfile(os.path.join(midi_path, m_fn)):\n",
    "            pm = pretty_midi.PrettyMIDI(os.path.join(midi_path, m_fn))\n",
    "            oh = utils.pretty_midi_to_one_hot(pm)\n",
    "            if type(oh) is not int:\n",
    "                oh = utils.slice_to_categories(oh)\n",
    "                #oh = oh.reshape(1, 128)\n",
    "                y_train.append(oh)\n",
    "        \n",
    "                im = Image.open(os.path.join(jpg_path, filename))\n",
    "                im = im.crop((14, 13, 594, 301))\n",
    "                resize = im.resize((49, 145), Image.NEAREST)\n",
    "                resize.load()\n",
    "                #result = Image.fromarray((visual * 255).astype(numpy.uint8))\n",
    "                #resize.save(\"images/\" + str(i) + \".jpg\")\n",
    "                arr = np.asarray(resize, dtype=\"float32\")\n",
    "                #print(arr)\n",
    "                #arr = block_reduce(arr, block_size=(2,2,1), func=np.mean)\n",
    "                x_train.append(arr)\n",
    "                #if len(x_train) > 0:\n",
    "                #    break\n",
    "                i += 1\n",
    "\n",
    "    x_train = np.array(x_train)\n",
    "    #x_train = x_train.reshape(len(x_train), 1)\n",
    "    y_train = np.array(y_train)\n",
    "    #print(y_train)\n",
    "    #print(x_train.shape)\n",
    "    #print(y_train.shape)\n",
    "    #print(len(x_train))\n",
    "    #print(np.shape(x_train))\n",
    "    #im_array = np.array([np.array\n",
    "    #x_train = np.array(x_train)\n",
    "    x_test = np.copy(x_train)\n",
    "    y_test = np.copy(y_train)\n",
    "    #x_train, x_test, y_train, y_test = train_test_split(\n",
    "    #        x_train, y_train, test_size=0.2, random_state=1)\n",
    "    #print(x_train.shape)\n",
    "    #print(y_train.shape)\n",
    "    x_train /= 255.0\n",
    "    x_test /= 255.0\n",
    "    train(x_train, y_train, x_test, y_test)\n",
    "\n",
    "\n",
    "run_cnn(sys.argv[1], sys.argv[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bbbc55-5507-412e-b084-1303e6a428b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
