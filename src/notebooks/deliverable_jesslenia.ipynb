{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f340a51e-6b19-4012-aea3-c2ae98a6e92b",
   "metadata": {},
   "source": [
    "#### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43d4ae9-48ec-489e-b0f6-4982dcee8ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Password:"
     ]
    }
   ],
   "source": [
    "!sudo apt update\n",
    "!sudo apt install musescore -y\n",
    "!pip install arvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6492b8e-9bf2-4c23-b919-0885901a22ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jessicakalip/Desktop/Apps/piano_transcription/src/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "503ed6ab-6b88-4963-b929-e58d8c4d6783",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'thepkg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m isfile, split, join\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01margparse\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthepkg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml_logic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_midi_to_wav, spectogram_stft, spectogram_cqt\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmidi2audio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FluidSynth\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'thepkg'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "from mido import MidiFile, MidiTrack, Message, MetaMessage\n",
    "from os import listdir\n",
    "from os.path import isfile, split, join\n",
    "import argparse\n",
    "from thepkg.ml_logic.preprocessor import convert_midi_to_wav, spectogram_stft, spectogram_cqt\n",
    "from midi2audio import FluidSynth\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import string\n",
    "from music21 import converter, corpus, instrument, midi, note, chord, pitch\n",
    "from music21 import * # import everything from music21\n",
    "from arvo import tools, isorhythm, minimalism, tintinnabuli\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c89a1f-cea8-4bfd-bc54-b9796ebeed53",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945494d8-595e-4b30-b010-8777baad604e",
   "metadata": {},
   "source": [
    "## Download 100 MIDI files and make them into 15 second chunks, and saved in data/short_midis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eab5f4-7e9e-4df3-ab47-d411781ee73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_midi_into_15_second_parts(src_midi_path='data/midis/enchanted.mid', dest_midi_base_path='data/short_midis/short_midis'):\n",
    "    src_midi = MidiFile(src_midi_path)\n",
    "\n",
    "    # Assuming a default tempo of 500,000 microseconds per beat\n",
    "    # Adjust this if your MIDI file specifies a different initial tempo\n",
    "    default_tempo = 500000\n",
    "    ticks_per_second = src_midi.ticks_per_beat * (default_tempo / 1000000)\n",
    "    ticks_for_2_seconds = ticks_per_second * 15\n",
    "\n",
    "    current_segment = 0\n",
    "    current_ticks_in_segment = 0\n",
    "\n",
    "    # Initialize the first segment MIDI file\n",
    "    segment_midi = MidiFile()\n",
    "    segment_midi.ticks_per_beat = src_midi.ticks_per_beat\n",
    "\n",
    "    for track in src_midi.tracks:\n",
    "        new_track = MidiTrack()\n",
    "        segment_midi.tracks.append(new_track)\n",
    "        for msg in track:\n",
    "            # Adjust for tempo changes if the message is a tempo change\n",
    "            if msg.type == 'set_tempo':\n",
    "                ticks_per_second = src_midi.ticks_per_beat * (msg.tempo / 1000000)\n",
    "                ticks_for_2_seconds = ticks_per_second * 15\n",
    "\n",
    "            # Check if adding the current message would exceed the 2-second limit for this segment\n",
    "            if current_ticks_in_segment + msg.time > ticks_for_2_seconds:\n",
    "                # Save the current segment MIDI file\n",
    "                segment_midi.save(f'{dest_midi_base_path}_part_{current_segment}.mid')\n",
    "\n",
    "                # Start a new segment MIDI file\n",
    "                segment_midi = MidiFile()\n",
    "                segment_midi.ticks_per_beat = src_midi.ticks_per_beat\n",
    "                new_track = MidiTrack()\n",
    "                segment_midi.tracks.append(new_track)\n",
    "\n",
    "                # Reset the tick count for the new segment and increment the segment counter\n",
    "                current_ticks_in_segment = 0\n",
    "                current_segment += 1\n",
    "\n",
    "            # Add the current message to the track and update the tick count\n",
    "            new_track.append(msg)\n",
    "            current_ticks_in_segment += msg.time\n",
    "\n",
    "    # Save the last segment if it has any content\n",
    "    if current_ticks_in_segment > 0:\n",
    "        segment_midi.save(f'{dest_midi_base_path}_part_{current_segment}.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d25d1b-986f-4d07-8866-7e22031f5b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Iterate over 100 MIDI files and call split_midi_into_15_second_parts()\n",
    "midis = os.listdir('data/midis')\n",
    "\n",
    "for midi in midis[0:10]:\n",
    "    midi_path = 'data/midis/' + midi\n",
    "    split_midi_into_15_second_parts(midi_path, 'data/short_midis/short_midis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ca49ad-88c3-459b-bf3f-0d213431325b",
   "metadata": {},
   "source": [
    "## X_train: convert short MIDI to wav, and then to STFT array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4403f84a-4e33-4da5-b809-b793820951b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: run spectogram_stft() on all short_midis and append to array X\n",
    "X = spectogram_stft('./data/short_midis/', \"./soundfont/FluidR3_GM.sf2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14f3081-009c-4683-a5b0-c4592f5e9cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1e2b8d-f2c0-4fc6-8083-5d0c23d9b650",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f71b51-f954-4792-8d1c-02f4870cd0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d28bb8-92ef-4ec2-9e37-765b9d28d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Attempt to reshape X before inputting to model\n",
    "reshaped_X = np.array(X).reshape(100, 1025, 500)\n",
    "reshaped_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b06388b-845c-498d-8357-3ff5ed542c3a",
   "metadata": {},
   "source": [
    "## y_train: convert short MIDI's to a number array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6164b0-cd9f-4fd4-9de0-a618db9b7b90",
   "metadata": {},
   "source": [
    "### midi to array function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcf83f3-5ab7-445f-b5f2-43f3bfa871fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def msg2dict(msg):\n",
    "    result = {}\n",
    "    if 'note_on' in msg:\n",
    "        on_ = True\n",
    "    elif 'note_off' in msg:\n",
    "        on_ = False\n",
    "    else:\n",
    "        on_ = None\n",
    "    result['time'] = int(msg[msg.rfind('time'):].split(' ')[0].split('=')[1].translate(\n",
    "        str.maketrans({a: None for a in string.punctuation})))\n",
    "\n",
    "    if on_ is not None:\n",
    "        for k in ['note', 'velocity']:\n",
    "            result[k] = int(msg[msg.rfind(k):].split(' ')[0].split('=')[1].translate(\n",
    "                str.maketrans({a: None for a in string.punctuation})))\n",
    "    return [result, on_]\n",
    "\n",
    "def switch_note(last_state, note, velocity, on_=True):\n",
    "    # piano has 88 notes, corresponding to note id 21 to 108, any note out of this range will be ignored\n",
    "    result = [0] * 88 if last_state is None else last_state.copy()\n",
    "    if 21 <= note <= 108:\n",
    "        result[note-21] = velocity if on_ else 0\n",
    "    return result\n",
    "\n",
    "def get_new_state(new_msg, last_state):\n",
    "    new_msg, on_ = msg2dict(str(new_msg))\n",
    "    new_state = switch_note(last_state, note=new_msg['note'], velocity=new_msg['velocity'], on_=on_) if on_ is not None else last_state\n",
    "    return [new_state, new_msg['time']]\n",
    "def track2seq(track):\n",
    "    # piano has 88 notes, corresponding to note id 21 to 108, any note out of the id range will be ignored\n",
    "    result = []\n",
    "    last_state, last_time = get_new_state(str(track[0]), [0]*88)\n",
    "    for i in range(1, len(track)):\n",
    "        new_state, new_time = get_new_state(track[i], last_state)\n",
    "        if new_time > 0:\n",
    "            result += [last_state]*new_time\n",
    "        last_state, last_time = new_state, new_time\n",
    "    return result\n",
    "\n",
    "def mid2arry(mid, min_msg_pct=0.1):\n",
    "    tracks_len = [len(tr) for tr in mid.tracks]\n",
    "    min_n_msg = max(tracks_len) * min_msg_pct\n",
    "    # convert each track to nested list\n",
    "    all_arys = []\n",
    "    for i in range(len(mid.tracks)):\n",
    "        if len(mid.tracks[i]) > min_n_msg:\n",
    "            ary_i = track2seq(mid.tracks[i])\n",
    "            if len(ary_i)==0:\n",
    "                pass\n",
    "            else:\n",
    "                all_arys.append(ary_i)\n",
    "                # make all nested list the same length\n",
    "                max_len = max([len(ary) for ary in all_arys])\n",
    "                for i in range(len(all_arys)):\n",
    "                    if len(all_arys[i]) < max_len:\n",
    "                        all_arys[i] += [[0] * 88] * (max_len - len(all_arys[i]))\n",
    "                all_arys = np.array(all_arys)\n",
    "                all_arys = all_arys.max(axis=0)\n",
    "                # trim: remove consecutive 0s in the beginning and at the end\n",
    "                sums = all_arys.sum(axis=1)\n",
    "                ends = np.where(sums > 0)[0]\n",
    "                return all_arys[min([0] if len(ends) == 0 else ends): max([0] if len(ends) == 0 else ends)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cf2cea-c31d-4775-a9b5-c95ee690812e",
   "metadata": {},
   "source": [
    "### Convert short_midis to midi_num_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a880570-1ac0-4b15-b7c2-84917806bacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_midis = os.listdir('data/short_midis')\n",
    "\n",
    "midi_arrays = []\n",
    "\n",
    "for midi in short_midis[0:100]:\n",
    "    thefile='./data/short_midis/' + midi\n",
    "    mid = MidiFile(thefile, clip=True)\n",
    "    myarray=mid2arry(mid)\n",
    "    midi_arrays.append(myarray)\n",
    "\n",
    "y = midi_arrays\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ba8073-495d-4ef4-8493-c414ef3751f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('len y:', len(y))\n",
    "y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb37a3a-5cf3-442c-991c-80d770bc5aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Notes: X is an stft dataframe (for GRU/LSTM model) & X is a spectogram (for CNN model), y is a numbered array of a MIDI \n",
    "## TODO: Ensure that X and y are of the same length\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921ba64d-a58e-42d9-86bf-20d925bb7cb7",
   "metadata": {},
   "source": [
    "# Modeling (GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c98ffb5-903a-4789-b33b-daaf35b18882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The GRU architecture\n",
    "model = Sequential()\n",
    "# First GRU layer with Dropout regularisation\n",
    "model.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation=‘tanh’))\n",
    "model.add(Dropout(0.2))\n",
    "# Second GRU layer\n",
    "model.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation=‘tanh’))\n",
    "model.add(Dropout(0.2))\n",
    "# Third GRU layer\n",
    "model.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation=‘tanh’))\n",
    "model.add(Dropout(0.2))\n",
    "# Fourth GRU layer\n",
    "model.add(GRU(units=50, activation=‘tanh’))\n",
    "model.add(Dropout(0.2))\n",
    "# The output layer\n",
    "model.add(Dense(units=1))\n",
    "# Compiling the RNN\n",
    "model.compile(optimizer=SGD(lr=0.01, decay=1e-7, momentum=0.9, nesterov=False),loss=‘mean_squared_error’)\n",
    "# Fitting to the training set\n",
    "model.fit(X_train,y_train,epochs=50,batch_size=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9567e5-a8df-4ad5-a2d5-11566be16bee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Modeling (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad75b355-e610-4422-ae81-dde029b1da52",
   "metadata": {},
   "source": [
    "# Result: Converting y_pred MIDI to Music Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775223fe-fb3a-4742-a119-bedbee129a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: return a y_pred (number array midi) from our model and convert to MIDI, then convert to music score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c679a2c9-123e-44a5-9ff2-fd7f64f5a235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arry2mid(ary, tempo=500000):\n",
    "    # get the difference\n",
    "    new_ary = np.concatenate([np.array([[0] * 88]), np.array(ary)], axis=0)\n",
    "    changes = new_ary[1:] - new_ary[:-1]\n",
    "    # create a midi file with an empty track\n",
    "    mid_new = MidiFile()\n",
    "    track = MidiTrack()\n",
    "    mid_new.tracks.append(track)\n",
    "    track.append(MetaMessage('set_tempo', tempo=tempo, time=0))\n",
    "    # add difference in the empty track\n",
    "    last_time = 0\n",
    "    for ch in changes:\n",
    "        if set(ch) == {0}:  # no change\n",
    "            last_time += 1\n",
    "        else:\n",
    "            on_notes = np.where(ch > 0)[0]\n",
    "            on_notes_vol = ch[on_notes]\n",
    "            off_notes = np.where(ch < 0)[0]\n",
    "            first_ = True\n",
    "            for n, v in zip(on_notes, on_notes_vol):\n",
    "                new_time = last_time if first_ else 0\n",
    "                track.append(Message('note_on', note=n + 21, velocity=v, time=new_time))\n",
    "                first_ = False\n",
    "            for n in off_notes:\n",
    "                new_time = last_time if first_ else 0\n",
    "                track.append(Message('note_off', note=n + 21, velocity=0, time=new_time))\n",
    "                first_ = False\n",
    "            last_time = 0\n",
    "    return mid_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d8e623-25d0-4dc2-a4fe-e20d4e1987a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_new = arry2mid(result_array, 545455)\n",
    "mid_new.save('mid_new.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcb8332-bb3e-4753-9eb5-31c873a1188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.set(\"musescoreDirectPNGPath\", '/opt/homebrew/bin/mscore') # tell music21 where MuseScore is installed\n",
    "\n",
    "def open_midi(midi_path):\n",
    "    # There is an one-line method to read MIDIs\n",
    "    # but to remove the drums we need to manipulate some\n",
    "    # low level MIDI events.\n",
    "    mf = midi.MidiFile()\n",
    "    mf.open(midi_path)\n",
    "    mf.read()\n",
    "    mf.close()\n",
    "\n",
    "    return midi.translate.midiFileToStream(mf)\n",
    "    \n",
    "base_midi = open_midi(\"ahmed2.mid\")\n",
    "base_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c7d5d7-cf5e-4be7-be4f-066497ac44d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Works on Linux...not Mac, should run hopefully :) \n",
    "base_midi.show()\n",
    "base_midi.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9fa0bb-2d2c-43e4-8ecc-fc0d7538e3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
